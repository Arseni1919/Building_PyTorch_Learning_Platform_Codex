{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision with Convolutional Networks\n",
    "\n",
    "Convolutional neural networks (CNNs) remain the workhorse of vision tasks because they exploit spatial locality and translation invariance. This notebook bridges beginner fundamentals with the attention-heavy models you will build later, emphasizing diagnostics and transfer learning.\n",
    "\n",
    "_Environment note:_ Network access is disabled here, so examples reflect APIs and best practices current through October 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- Explain how convolution, pooling, and normalization create feature hierarchies.\n",
    "- Build and visualize activations of a small CNN in PyTorch.\n",
    "- Simulate transfer learning by freezing backbones and attaching custom heads.\n",
    "- Prepare for transformer-based vision models by practicing residual patterns and diagnostic plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Hierarchies at a Glance\n",
    "\n",
    "- Early layers capture simple edges and textures.\n",
    "- Intermediate layers assemble motifs (corners, contours).\n",
    "- Deep layers respond to semantic regions of the input.\n",
    "\n",
    "This inductive bias—weight sharing and local connectivity—keeps CNNs competitive even alongside attention models like ViT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n", 
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model = SmallCNN()\n",
    "dummy_images = torch.randn(4, 3, 32, 32)\n",
    "logits = model(dummy_images)\n",
    "print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Feature Maps\n",
    "\n",
    "Hooks let you capture intermediate activations for diagnostics. This is invaluable when a training run underperforms—you can reveal whether the network is extracting meaningful structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = {}\n",
    "\n",
    "def save_activation(name):\n",
    "    def hook(module, _input, output):\n",
    "        feature_maps[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.features[0].register_forward_hook(save_activation(\"conv1\"))\n",
    "model.features[4].register_forward_hook(save_activation(\"conv2\"))\n",
    "_ = model(dummy_images)\n",
    "\n",
    "for name, activation in feature_maps.items():\n",
    "    print(name, activation.shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for idx, ax in enumerate(axes):\n",
    "    ax.imshow(feature_maps[\"conv1\"][0, idx].cpu(), cmap=\"viridis\")\n",
    "    ax.axis(\"off\")\n",
    "fig.suptitle(\"First-layer filters responding to a synthetic sample\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Task – Freeze the Backbone\n",
    "\n",
    "Simulate transfer learning: freeze the convolutional backbone, leave the classifier trainable, and report the number of parameters still being updated.\n",
    "\n",
    "Complete the task before expanding the hidden solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_backbone(model: nn.Module):\n",
    "    # TODO: set requires_grad appropriately\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def freeze_backbone(model: nn.Module):\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "freeze_backbone(model)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Pattern\n",
    "\n",
    "Load a pretrained backbone, freeze most layers, and fine-tune a small head on your dataset. The snippet below uses torchvision; adapt the head architecture to match your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torchvision.models as models\n",
    "except ImportError:\n",
    "    models = None\n",
    "\n",
    "if models is not None:\n",
    "    backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    for param in backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    backbone.fc = nn.Sequential(\n",
    "        nn.Linear(backbone.fc.in_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, 10),\n",
    "    )\n",
    "    print(\"Transfer learning model ready (requires torchvision)\")\n",
    "else:\n",
    "    print(\"torchvision not available; install it to run the transfer learning example\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Exercise – Configurable CNN Builder\n",
    "\n",
    "Implement `build_cnn(config)` that accepts channel widths, kernel sizes, optional batch norm, and residual blocks. Return an `nn.Sequential` model. Instantiate baseline and deeper configurations and summarize parameter counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(config):\n",
    "    # TODO: construct sequential CNN based on configuration dictionary\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def conv_block(in_c, out_c, kernel_size, use_bn=True):\n",
    "    layers = [nn.Conv2d(in_c, out_c, kernel_size=kernel_size, padding=kernel_size // 2), nn.ReLU(inplace=True)]\n",
    "    if use_bn:\n",
    "        layers.insert(1, nn.BatchNorm2d(out_c))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResidualConvBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=3, use_bn=True):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            conv_block(channels, channels, kernel_size, use_bn),\n",
    "            conv_block(channels, channels, kernel_size, use_bn),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "def build_cnn(config):\n",
    "    channels = config[\"channels\"]\n",
    "    kernel_sizes = config.get(\"kernel_sizes\", [3] * len(channels))\n",
    "    use_bn = config.get(\"use_batchnorm\", True)\n",
    "    residual = config.get(\"residual\", False)\n",
    "\n",
    "    layers = []\n",
    "    in_c = 3\n",
    "    for idx, out_c in enumerate(channels):\n",
    "        k = kernel_sizes[idx]\n",
    "        layers.append(conv_block(in_c, out_c, k, use_bn))\n",
    "        if residual and idx > 0:\n",
    "            layers.append(ResidualConvBlock(out_c, kernel_size=k, use_bn=use_bn))\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "        in_c = out_c\n",
    "    layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Linear(in_c, config.get(\"num_classes\", 10)))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "baseline_cfg = {\"channels\": [32, 64], \"kernel_sizes\": [3, 3], \"use_batchnorm\": True, \"residual\": False}\n",
    "deeper_cfg = {\"channels\": [32, 64, 128], \"kernel_sizes\": [3, 3, 3], \"use_batchnorm\": True, \"residual\": True}\n",
    "\n",
    "baseline = build_cnn(baseline_cfg)\n",
    "deeper = build_cnn(deeper_cfg)\n",
    "\n",
    "print(\"Baseline params:\", sum(p.numel() for p in baseline.parameters()))\n",
    "print(\"Deeper params:\", sum(p.numel() for p in deeper.parameters()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- PyTorch vision tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "- He et al. (2015) “Deep Residual Learning for Image Recognition”\n",
    "- Albumentations and torchvision transforms for richer augmentations\n",
    "- Papers With Code Vision benchmarks for architecture inspiration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
